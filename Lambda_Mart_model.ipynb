{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A_3pF7Y2au_i"
   },
   "source": [
    "# **Importing libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2022-07-26T06:13:13.213642Z",
     "iopub.status.busy": "2022-07-26T06:13:13.213248Z",
     "iopub.status.idle": "2022-07-26T06:14:02.917510Z",
     "shell.execute_reply": "2022-07-26T06:14:02.916337Z",
     "shell.execute_reply.started": "2022-07-26T06:13:13.213611Z"
    },
    "id": "_y1mTvyyau_s",
    "outputId": "827cbc57-59ca-4605-cdae-5a405736ad8b"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import copy\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from multiprocessing import Pool\n",
    "from datetime import datetime\n",
    "import math\n",
    "\n",
    "# NLTK Stopwords\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Fasttext\n",
    "!pip install fasttext\n",
    "import fasttext\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# To get vector embeddings\n",
    "!pip install sister\n",
    "import sister\n",
    "\n",
    "# Processing Parquets\n",
    "!pip install fastparquet\n",
    "!unzip Training_DSF.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vCd-EP3-au_x"
   },
   "source": [
    "# **Preparing the Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "execution": {
     "iopub.execute_input": "2022-07-26T06:20:16.402995Z",
     "iopub.status.busy": "2022-07-26T06:20:16.402589Z",
     "iopub.status.idle": "2022-07-26T06:25:18.891717Z",
     "shell.execute_reply": "2022-07-26T06:25:18.890469Z",
     "shell.execute_reply.started": "2022-07-26T06:20:16.402964Z"
    },
    "id": "ObCYbDplau_y",
    "outputId": "7f3f7d1d-ffaf-41f5-9eba-ba455d0e8a96"
   },
   "outputs": [],
   "source": [
    "sentence_embedding = sister.MeanEmbedding(lang=\"en\")\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "import os\n",
    "directory = '/content/Training_DSF'\n",
    "entries = os.listdir('/content/Training_DSF')\n",
    "file_count = len([item for item in os.listdir(directory) if os.path.isfile(os.path.join(directory, item))])\n",
    "article_prod = pd.DataFrame(columns = [])\n",
    " \n",
    "# append datasets to the list\n",
    "for i in range(file_count):\n",
    "    temp_df = pd.read_parquet('/content/Training_DSF/'+entries[i])\n",
    "    article_prod=article_prod.append(temp_df)\n",
    "print(article_prod  ) \n",
    "#article_prod = pd.read_parquet('/content/Training_DS.zip', engine='fastparquet')\n",
    "article_prod = article_prod.drop_duplicates(subset='id', keep=\"first\")\n",
    "article_prod = article_prod.drop('mid', axis=1)\n",
    "article_prod = article_prod.drop('slug', axis=1)\n",
    "article_prod = article_prod.drop('imageUrl', axis=1)\n",
    "article_prod = article_prod.drop('metaDescription', axis=1)\n",
    "article_prod = article_prod.drop('offset', axis=1)\n",
    "article_prod = article_prod.drop('partition', axis=1)\n",
    "article_prod = article_prod.drop('processTimestamp', axis=1)\n",
    "article_prod = article_prod.drop('contentType', axis=1)\n",
    "article_prod = article_prod.drop('updatedTimestamp', axis=1)\n",
    "article_prod = article_prod.drop('hour', axis=1)\n",
    "\n",
    "article_prod = article_prod.dropna()\n",
    "article_prod['headline'] = article_prod['headline'].apply(lambda words: ' '.join(word.lower() for word in words.split() if word not in stop_words))\n",
    "cleaned_text = article_prod['text'].apply(lambda words: ' '.join(word.lower() for word in words.split() if word not in stop_words))\n",
    "cleaned_tags = article_prod['tagName'].apply(lambda words: ' '.join(word.lower() for word in words.split() if word not in stop_words))\n",
    "\n",
    "article_prod"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pyah7UrWau_0"
   },
   "source": [
    "# Creating the Headline, Text, and Tag Similarity Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-26T06:28:10.477299Z",
     "iopub.status.busy": "2022-07-26T06:28:10.476871Z",
     "iopub.status.idle": "2022-07-26T06:28:10.625948Z",
     "shell.execute_reply": "2022-07-26T06:28:10.624543Z",
     "shell.execute_reply.started": "2022-07-26T06:28:10.477263Z"
    },
    "id": "MF5KEe_qau_2"
   },
   "outputs": [],
   "source": [
    "def create_matrix(list):\n",
    "    tensor_list = []\n",
    "    for i in list:\n",
    "        tensor_list.append(torch.tensor(sentence_embedding(i)))\n",
    "    # Now we have the list of tensors.\n",
    "    matrix = []\n",
    "    for i in tensor_list:\n",
    "        tmplist = []\n",
    "        for j in tensor_list:\n",
    "            tmplist.append(F.cosine_similarity(i, j, dim=0))\n",
    "        matrix.append(tmplist)\n",
    "    return matrix\n",
    "    \n",
    "headline_matrix = create_matrix(article_prod['headline'])\n",
    "text_matrix = create_matrix(cleaned_text)\n",
    "tag_matrix = create_matrix(cleaned_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t9e2-Jidau_3"
   },
   "source": [
    "# Creating the Time Difference Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-26T06:28:31.188911Z",
     "iopub.status.busy": "2022-07-26T06:28:31.188144Z",
     "iopub.status.idle": "2022-07-26T06:28:31.204562Z",
     "shell.execute_reply": "2022-07-26T06:28:31.203797Z",
     "shell.execute_reply.started": "2022-07-26T06:28:31.188871Z"
    },
    "id": "ASYCzwB_au_5"
   },
   "outputs": [],
   "source": [
    "n = article_prod.shape[0]\n",
    "time_matrix = [[0 for x in range(n)] for y in range(n)] \n",
    "time_diff = []\n",
    "for i in range(n):\n",
    "    for j in range(n):\n",
    "        time_matrix[i][j]= (datetime.strptime(article_prod['date'].values[i], \"%Y-%m-%d\")-datetime.strptime(article_prod['date'].values[j], \"%Y-%m-%d\")).days"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rvD3KqHCau_6"
   },
   "source": [
    "# Combining Text/Headline similarity, and Time difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 641
    },
    "execution": {
     "iopub.execute_input": "2022-07-26T06:28:34.641510Z",
     "iopub.status.busy": "2022-07-26T06:28:34.640372Z",
     "iopub.status.idle": "2022-07-26T06:28:35.239805Z",
     "shell.execute_reply": "2022-07-26T06:28:35.238537Z",
     "shell.execute_reply.started": "2022-07-26T06:28:34.641474Z"
    },
    "id": "plgLeuELau_7",
    "outputId": "1dc6e01b-7e38-4585-ffdc-202964983bbe"
   },
   "outputs": [],
   "source": [
    "final_dataframe = pd.DataFrame(columns = ['qid', 'id', 'grade' ,'features'])\n",
    "\n",
    "# TODO: Figure out a proper value for the grades.\n",
    "def findGrade(num):\n",
    "  if(0.00 <= num and num < 0.1175 ):\n",
    "     return 0\n",
    "  elif (0.1175 < num and num < 0.2212):\n",
    "     return 1\n",
    "  elif(0.2212 < num and num < 0.393):\n",
    "     return 2\n",
    "  elif(0.393< num and num < 0.632  ):\n",
    "      return 3\n",
    "  elif(0.632 < num and num < 0.865):\n",
    "      return 4\n",
    "  else:\n",
    "      return 5\n",
    "\n",
    "for i in range(n):\n",
    "    for j in range(n):\n",
    "        if(i==j): continue;\n",
    "        tmp = {'headline_qid':article_prod['headline'].values[i],'headline_id':article_prod['headline'].values[j],'qid': article_prod['id'].values[i], 'id': article_prod['id'].values[j], 'grade': findGrade(headline_matrix[i][j].item()),'features' : [text_matrix[i][j].item(),tag_matrix[i][j].item(),math.exp(-time_matrix[i][j])]}\n",
    "        final_dataframe = final_dataframe.append(tmp,ignore_index=True)\n",
    "        \n",
    "final_dataframe['group_id']=final_dataframe.groupby(['qid'])['id'].ngroup()\n",
    "final_dataframe['last_prediction'] = 0.0\n",
    "final_dataframe = final_dataframe.sort_values(['group_id', 'last_prediction'], ascending=[True, False], kind='stable')\n",
    "final_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j3O5m1sDau_9"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UVuqXvC7au_9"
   },
   "outputs": [],
   "source": [
    "\n",
    "def compute_lambdas(lambdas_per_query):\n",
    "    lambdas_per_query = lambdas_per_query.sort_values(['group_id', 'last_prediction'], ascending=[True, False], kind='stable')\n",
    "    lambdas_per_query['display_rank'] = lambdas_per_query.groupby('group_id').cumcount()\n",
    "\n",
    "    #TBD - How do generalize this to any metric?\n",
    "    lambdas_per_query['discount'] = 1 / np.log2(2 + lambdas_per_query['display_rank'])\n",
    "    lambdas_per_query['gain'] = (2**lambdas_per_query['grade'] - 1)\n",
    "\n",
    "    # swaps dataframe holds each pair-wise swap computed (shrink columns for memory?)   \n",
    "    # Optimization of swaps = lambdas_per_query.merge(lambdas_per_query, on='qid', how='outer')\n",
    "    # to limit to just needed columns\n",
    "    to_swap = lambdas_per_query[['group_id', 'display_rank', 'grade', 'last_prediction', 'discount', 'gain']]\n",
    "    #to_swap = lambdas_per_query\n",
    "    swaps = to_swap.merge(to_swap, on='group_id', how='outer')\n",
    "\n",
    "    # delta - delta in DCG due to swap\n",
    "    swaps['delta'] = np.abs((swaps['discount_x'] - swaps['discount_y']) * (swaps['gain_x'] - swaps['gain_y']))\n",
    "    \n",
    "    # rho - based on current model prediction delta\n",
    "    swaps['rho'] = 1 / (1 + np.exp(swaps['last_prediction_x'] - swaps['last_prediction_y']))\n",
    "    \n",
    "    # If you want to be pure gradient boosting, weight reweights each models prediction\n",
    "    # I haven't found this to matter in practice\n",
    "    swaps['weight'] = swaps['rho'] * (1.0 - swaps['rho']) * swaps['delta']\n",
    "\n",
    "    # Compute lambdas (the next model in ensemble's predictors) when grade_x > grade_y\n",
    "    swaps['lambda'] = 0\n",
    "    slice_x_better =swaps[swaps['grade_x'] > swaps['grade_y']]\n",
    "    swaps.loc[swaps['grade_x'] > swaps['grade_y'], 'lambda'] = slice_x_better['delta'] * slice_x_better['rho']\n",
    "    \n",
    "    # accumulate lambdas and add back to model\n",
    "    lambdas_x = swaps.groupby(['group_id', 'display_rank_x'])['lambda'].sum().rename('lambda')\n",
    "    lambdas_y = swaps.groupby(['group_id', 'display_rank_y'])['lambda'].sum().rename('lambda')\n",
    "\n",
    "    weights_x = swaps.groupby(['group_id', 'display_rank_x'])['weight'].sum().rename('weight')\n",
    "    weights_y = swaps.groupby(['group_id', 'display_rank_y'])['weight'].sum().rename('weight')\n",
    "    \n",
    "    weights = weights_x + weights_y\n",
    "    lambdas = lambdas_x - lambdas_y\n",
    "\n",
    "    lambdas_per_query = lambdas_per_query.merge(lambdas, \n",
    "                                                left_on=['group_id', 'display_rank'], \n",
    "                                                right_on=['group_id', 'display_rank_x'], \n",
    "                                                how='left')\n",
    "    lambdas_per_query = lambdas_per_query.merge(weights, \n",
    "                                                left_on=['group_id', 'display_rank'], \n",
    "                                                right_on=['group_id', 'display_rank_x'], \n",
    "                                                how='left')\n",
    "\n",
    "    return lambdas_per_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_ZmO6Ez-au__",
    "outputId": "6c641818-f326-4d67-b965-9b2523f3c9a6"
   },
   "outputs": [],
   "source": [
    "ensemble=[]\n",
    "def lambda_mart_pure(final_dataframe, rounds=20,\n",
    "                     learning_rate=0.1, max_leaf_nodes=8):\n",
    "\n",
    "    lambdas_per_query = final_dataframe.copy()\n",
    "    lambdas_per_query['last_prediction'] = 0.0\n",
    "\n",
    "    for i in range(0, rounds):\n",
    "        print(f\"round {i}\")\n",
    "\n",
    "        # ------------------\n",
    "        #1. Build pair-wise predictors for this round\n",
    "        lambdas_per_query = compute_lambdas(lambdas_per_query)\n",
    "\n",
    "\n",
    "        # ------------------\n",
    "        #2. Train a regression tree on this round's lambdas\n",
    "        features = lambdas_per_query['features'].tolist()\n",
    "        new_tree = DecisionTreeRegressor(max_leaf_nodes=max_leaf_nodes)\n",
    "        new_tree.fit(features, lambdas_per_query['lambda'])    \n",
    "\n",
    "        # -------------------\n",
    "        #4. Add to ensemble, recreate last prediction\n",
    "        ensemble.append(new_tree)\n",
    "        next_predictions = new_tree.predict(features)\n",
    "        lambdas_per_query['last_prediction'] += (next_predictions * learning_rate) \n",
    "        \n",
    "        print(lambdas_per_query.loc[0, ['grade', 'last_prediction']])\n",
    "        \n",
    "        print(\"Train DCGs\")\n",
    "        lambdas_per_query['discounted_gain'] = lambdas_per_query['gain'] * lambdas_per_query['discount'] \n",
    "        dcg = lambdas_per_query[lambdas_per_query['display_rank'] < 10].groupby('qid')['discounted_gain'].sum().mean()\n",
    "        print(\"mean   \", dcg)\n",
    "        print(\"----------\")\n",
    "        \n",
    "        lambdas_per_query = lambdas_per_query.drop(['lambda', 'weight'], axis=1)\n",
    "    return lambdas_per_query\n",
    "\n",
    "\n",
    "lambdas_per_query = lambda_mart_pure(final_dataframe=final_dataframe, rounds=50, max_leaf_nodes=10, learning_rate=0.01)\n",
    "model = ensemble[len(ensemble) -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WVIHEnehavAA"
   },
   "outputs": [],
   "source": [
    "import heapq\n",
    "r = final_dataframe.shape[0]\n",
    "# Given an article id\n",
    "def rank(article_h,m):\n",
    " H = []\n",
    " \n",
    " for i in range(r):\n",
    "     if(article_h == final_dataframe.iloc[i]['headline_qid']):\n",
    "         heapq.heappush(H,[-model.predict(np.array(final_dataframe.iloc[i]['features']).reshape(1, -1)),final_dataframe.iloc[i]['headline_id']])\n",
    " k_elems = []\n",
    " for i in range(m):\n",
    "     k_elems.append(heapq.heappop(H))\n",
    " return k_elems  \n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WrRxWm4GyE_Q",
    "outputId": "76213c0d-0b6f-432f-e5d7-4b2aac67702c"
   },
   "outputs": [],
   "source": [
    "z=np.array_split(rank('kbc 13: amitabh bachchan recalls when farah khan scolded him set',10),10)\n",
    "print(\"the ranked list of articles is :\")\n",
    "print (z)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lNfXnBO-g1De",
    "outputId": "75cc51ef-3a6b-48ba-9bc8-6fcca6c944d0"
   },
   "outputs": [],
   "source": [
    "print(\"The ranked list of articles is :\")\n",
    "for i in range(10):\n",
    "  print(i+1,\". \",end=\"\")\n",
    "  print(z[i][0][1])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "learning_to_rank_article_prod_fdac6b.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
